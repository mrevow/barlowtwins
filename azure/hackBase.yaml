log_file: ''
debug: False
log_upload_files: True
logger_type: pipeline
config_file_delete_on_exit: True

operations: [train_unsupervised] # train_unsupervised | train_supervised | eval_unsupervised

workers: 8
num_gpu: !!null   # Number of gpus to use None means use all available
epochs: 1000
batch_size: 512
learning_rate_weights: 0.2
learning_rate_biases: 0.0048  # base learning rate for biases and batch norm parameters
weight_decay: 0.000001
lambd: 0.0051   # Weight on off diagonal terms
val_freq: 4
early_stop_patience: 20
projector: '8192-8192-8192'  # Projector MLP
print_freq: 10000
plot_freq: 100
checkpoint_name: barlow_checkpoint.pth
backend: nccl
master_port: '9756'
backbone_model: Cnn6
backbone_kwargs: [{'sample_rate': 16000, 'window_size': 1024, 'hop_size': 800, 'mel_bins': 64, 'fmin': 0, 'fmax': 8000, 'classes_num': 2 }]

music_classifier_freeze_backbone: false
music_classifier_epochs: 1000
music_classifier_checkpoint_name: music_checkpoint.pth
music_classifier_learning_rate: 0.0001 # learning rate for supervised training
music_classifier_early_stop_patience: 100
music_classifier_early_stop_metric: rec@_0.99
music_classifier_metrics_at_recall: [0.85, 0.95]  # Precision at recall
music_classifier_metrics_at_precision: [0.95, 0.99]  # Recall at precision
music_classifier_metrics_at_fpr: [0.1, 0.2,]  # TPR at FPR
music_classifier_metrics_at_tpr: [0.95, 0.99]  # FPR at TPR
music_classifier_metrics_plt_pause_delay_sec: -1  # setting > 0 will show the metrics plots for local runs no impact on AML

# Data
data_train_bin_path: ['hack/music-detection-data/sl_training_set_v1']  # relative path to the binary data files
data_train_view_files: ['hack/trainConfigs/unsupervised_train_v04.txt']   # relative path to the train view file lists
data_val_bin_path: ['hack/music-detection-data/sl_training_set_v1/'] 
data_val_view_files: ['hack/trainConfigs/unsupervised_val_v04.txt']

data_suptrain_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised training
data_suptrain_view_files: ['hack/trainConfigs/supervised_train_v04.txt']    # supervised training
data_supval_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised val (during train)
data_supval_view_files: ['hack/trainConfigs/supervised_val_v04.txt']    # supervised val (during train)
data_suptest_bin_path: ['hack/music-detection-data/test_set'] # supervised eval run
data_suptest_view_files: ['hack/trainConfigs/test.txt']    # supervised eval run

data_num_retry: 10 # Maximum number of retries when  clip cannot be loaded
data_samp_rate: 16000
data_plot_max_limits: {'us_loss': 10000, 'val_loss': 10000, 'auc': 1.0}
data_plot_min_limits: {'us_loss': 0.0, 'val_loss': 0.0, 'auc': 0.0}
data_epoch_checkpoint_freq: 5
data_pad_duration: 10 # files short than data_pad_duration seconds will be zero padded
data_short_thresh: 9  # Clips shorter than this are skipped

# Transforms must be one of torchAudio transforms - see https://pytorch.org/audio/stable/transforms.html
# Each entry is a tuple [TransformName, arguments]
data_transforms_1: [
    ['SoxPitchTransform', {'pRange': 50}], # +- pRange shift in cent
    ['WhiteNoiseTransform', {'snrLow': 20, 'snrHigh': 60}], # SNR in dB 
    ['PolarityTransform', {}], # applied in 50% of cases
    ['SoxGainTransform', {'gain': -10}], # reduces level from [gain to 0] dB

    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}] 
]
data_transforms_2: [ 
    ['SoxPitchTransform', {'pRange': 50}], # pRange is +- cent
    ['WhiteNoiseTransform', {'snrLow': 20, 'snrHigh': 60}], 
    ['PolarityTransform', {}], # applied in 50% of cases
    ['SoxGainTransform', {'gain': -10}], # reduces level from [gain to 0] dB

    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}] 
  ]

data_sup_transforms: [ 
    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}] 
  ]

# These transforms take place on the batch data sent to the Barlow model
data_batch_transforms_1: [
    ['NormalizeInputBatch', {'chanCount': 64, 'transpose': [1, 2]}] 
  ]
data_batch_transforms_2: [
    ['NormalizeInputBatch', {'chanCount': 64, 'transpose': [1, 2]}] 
  ]