_include: !include hackBase.yaml

epochs: 10000
batch_size: 512
val_freq: 4
early_stop_patience: 20

music_classifier_epochs: 10000
music_classifier_learning_rate: 0.0001
music_classifier_early_stop_patience: 20

data_train_bin_path: ['hack/music-detection-data/sl_training_set_v1/', 'hack/music-detection-data/music-detection-unlabeled/', 'hack/music-detection-data/audioset/']  # relative path to the binary data files
data_train_view_files: ['hack/trainConfigs/supervised_train_v04.txt', 'hack/trainConfigs/music_notLabeled_16572_10secOnly.txt', 'hack/trainConfigs/audioset_470742_16000.txt']   # relative path to the train view file lists
data_val_bin_path: ['hack/music-detection-data/sl_training_set_v1/'] 
data_val_view_files: ['hack/trainConfigs/unsupervised_val_v04.txt']

print_freq: 50
plot_freq: 4


# For short tests
# data_train_bin_path: ['hack/music-detection-data/sl_training_set_v1']  # relative path to the binary data files
# data_train_view_files: ['hack/trainConfigs/short_40.txt']   # relative path to the train view file lists
# data_val_bin_path: ['hack/music-detection-data/sl_training_set_v1']  # relative path to the binary data files
# data_val_view_files: ['hack/trainConfigs/short_40_val.txt']   # relative path to the train view file lists
# data_suptrain_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised training
# data_suptrain_view_files: ['hack/trainConfigs/short_40.txt']    # supervised training
# data_supval_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised val (during train)
# data_supval_view_files: ['hack/trainConfigs/short_40_val.txt']    # supervised val (during train)
# data_suptest_view_files: ['hack/trainConfigs/test.txt']    # supervised eval run
# data_suptest_bin_path: ['hack/music-detection-data/test_set'] # supervised eval run)


operations: ['train_unsupervised', 'train_supervised', 'eval_supervised']

# To use a torchvision Net
backbone_model: resnet18
backbone_kwargs: [{ "zero_init_residual": True}]

data_plot_min_limits: {'loss': 0.0}
data_plot_max_limits: {'loss': 12000.0}
data_plot_min_limits: {'val_loss': 0.0}
data_plot_max_limits: {'val_loss': 12000.0}


data_transforms_1: [
    ['SoxEffectTransform', {'effects': [['pitch', '5'], ['gain', '-n']]}],
    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}],
  ]
data_transforms_2: [
    ['SoxEffectTransform', {'effects': [['pitch', '5'], ['gain', '-n']]}],
    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}],
  ]

data_sup_transforms: [ 
    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}] 
  ]
