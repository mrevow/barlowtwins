_include: !include hackBase.yaml

epochs: 75
batch_size: 1024
data_train_bin_path: ['hack/music-detection-data/sl_training_set_v1/', 'hack/music-detection-data/music-detection-unlabeled/']  # relative path to the binary data files
data_train_view_files: ['hack/trainConfigs/train_unsupervised.txt', 'hack/trainConfigs/music_notLabeled_16572_10secOnly.txt']   # relative path to the train view file lists
print_freq: 50
plot_freq: 5
debug: True
# data_suptrain_bin_path: ['hack/music-detection-data/sl_training_set_v1']  # relative path to the binary data files
# data_supval_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised only

print_freq: 100

# operations: ['train_unsupervised', 'train_supervised', 'eval_supervised']
# operations: [ 'train_supervised']
# operations: ['data_ops']
# data_ops: ['clipListByDir', ]
# data_analysis_outputfile: data.log

music_classifier_epochs: 20

# To use a torchvision Net
backbone_model: resnet18
backbone_kwargs: [{ "zero_init_residual": True}]

data_plot_min_limits: {'loss': 0.0}
data_plot_max_limits: {'loss': 12000.0}

data_transforms_1: [
    ['LibrPitch', {'sr': 16000, 'pRange': 6}],
    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}],
  ]
data_transforms_2: [
    ['LibrPitch', {'sr': 16000, 'pRange': 6}],
    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}],
  ]

