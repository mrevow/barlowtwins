_include: !include hackBase.yaml

epochs: 50
music_classifier_epochs: 50
batch_size: 1024
data_train_bin_path: ['hack/music-detection-data/sl_training_set_v1/', 'hack/music-detection-data/music-detection-unlabeled/']  # relative path to the binary data files
data_train_view_files: ['hack/trainConfigs/train_unsupervised.txt', 'hack/trainConfigs/music_notLabeled_16572_10secOnly.txt']   # relative path to the train view file lists
print_freq: 50
plot_freq: 5

# For short tests
# data_train_bin_path: ['hack/music-detection-data/sl_training_set_v1']  # relative path to the binary data files
# data_train_view_files: ['hack/trainConfigs/short_40.txt']   # relative path to the train view file lists
# data_suptrain_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised training
# data_suptrain_view_files: ['hack/trainConfigs/short_40.txt']    # supervised training
# data_supval_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised val (during train)
# data_supval_view_files: ['hack/trainConfigs/short_40.txt']    # supervised val (during train)
# data_supval_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised val (during train
# data_suptest_view_files: ['hack/trainConfigs/short_40.txt']    # supervised eval run
# data_suptest_bin_path: ['hack/music-detection-data/sl_training_set_v1'] # supervised eval run)


operations: ['train_unsupervised', 'train_supervised', 'eval_supervised']


# To use a torchvision Net
backbone_model: resnet18
backbone_kwargs: [{ "zero_init_residual": True}]

data_plot_min_limits: {'loss': 0.0}
data_plot_max_limits: {'loss': 12000.0}

data_transforms_1: [
    ['LibrPitch', {'sr': 16000, 'pRange': 6}],
    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}],
  ]
data_transforms_2: [
    ['LibrPitch', {'sr': 16000, 'pRange': 6}],
    ['MelSpectrogram' , {'n_fft': 1024, 'hop_length': 800, 'n_mels': 64}],
    ['ExpandDim', {'dim': 0}],
  ]

